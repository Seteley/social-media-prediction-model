# FINAL_MODELO_REGRESION: Documentaci贸n Completa de Modelos de Regresi贸n

##  Documentaci贸n T茅cnica de los 8 Modelos de Regresi贸n - TwiTrack API

**Versi贸n:** 3.0.0  
**Fecha:** Julio 2025  
**Sistema:** TwiTrack - An谩lisis Predictivo de Redes Sociales

---

##  ndice

1. [Informaci贸n General](#informaci贸n-general)
2. [Configuraci贸n de Entrada](#configuraci贸n-de-entrada)
3. [Modelos de Regresi贸n](#modelos-de-regresi贸n)
4. [M茅tricas de Evaluaci贸n](#m茅tricas-de-evaluaci贸n)
5. [Selecci贸n del Mejor Modelo](#selecci贸n-del-mejor-modelo)
6. [Salidas del Sistema](#salidas-del-sistema)
7. [Ejemplo de Uso](#ejemplo-de-uso)

---

##  Informaci贸n General

### **Objetivo**
Predicci贸n del n煤mero de seguidores en redes sociales utilizando m茅tricas de engagement temporal para cuentas del sector financiero peruano.

### **Tipo de Problema**
Regresi贸n supervisada multi-modelo con selecci贸n autom谩tica del mejor algoritmo.

### **Variable Objetivo**
- **Target:** `seguidores` (n煤mero de seguidores de la cuenta)

### **Features de Entrada**
- **dia_semana:** D铆a de la semana (0-6, donde 0=Lunes)
- **hora:** Hora del d铆a (0-23)
- **mes:** Mes del a帽o (1-12)

---

## 锔 Configuraci贸n de Entrada

### **Preparaci贸n de Datos**
```python
# Divisi贸n de datos
test_size: 0.2 (20% para prueba)
random_state: 42 (reproducibilidad)
cv_folds: 5 (validaci贸n cruzada)

# Preprocesamiento
fillna: 0 (valores faltantes)
scaling: No requerido (features num茅ricas simples)
```

### **Validaci贸n de Entrada**
- Verificaci贸n de variable objetivo en dataset
- Filtrado de features disponibles
- Manejo autom谩tico de valores faltantes
- Validaci贸n de dimensiones m铆nimas

---

##  Modelos de Regresi贸n

### **1. Regresi贸n Lineal Simple**
```python
Modelo: LinearRegression
Par谩metros: {}
Descripci贸n: Regresi贸n Lineal Simple

Caracter铆sticas:
- Modelo baseline m谩s simple
- Relaci贸n lineal entre features y target
- Interpretabilidad m谩xima
- Sin regularizaci贸n

Ventajas:
- R谩pido entrenamiento e inferencia
- F谩cil interpretaci贸n de coeficientes
- Estable y robusto

Desventajas:
- Asume relaciones lineales
- Sensible a outliers
- No maneja interacciones complejas
```

### **2. Regresi贸n Ridge (L2)**
```python
Modelo: Ridge
Par谩metros: {
    'alpha': 1.0,
    'random_state': 42
}
Descripci贸n: Regresi贸n Ridge (L2)

Caracter铆sticas:
- Regularizaci贸n L2 (penaliza coeficientes grandes)
- Reduce overfitting
- Mantiene todas las features

Ventajas:
- Mejor generalizaci贸n que regresi贸n lineal
- Maneja multicolinealidad
- Estable num茅ricamente

Desventajas:
- No elimina features irrelevantes
- Requiere tuning de alpha
- Menos interpretable que lineal simple
```

### **3. Regresi贸n Lasso (L1)**
```python
Modelo: Lasso
Par谩metros: {
    'alpha': 1.0,
    'random_state': 42
}
Descripci贸n: Regresi贸n Lasso (L1)

Caracter铆sticas:
- Regularizaci贸n L1 (puede eliminar features)
- Selecci贸n autom谩tica de features
- Soluci贸n sparse

Ventajas:
- Selecci贸n autom谩tica de features
- Reduce dimensionalidad
- Interpretable (coeficientes cero)

Desventajas:
- Puede eliminar features importantes
- Inestable con features correlacionadas
- Requiere tuning de alpha
```

### **4. Random Forest**
```python
Modelo: RandomForestRegressor
Par谩metros: {
    'n_estimators': 100,
    'random_state': 42
}
Descripci贸n: Random Forest

Caracter铆sticas:
- Ensemble de 谩rboles de decisi贸n
- Bootstrap aggregating (bagging)
- Maneja interacciones no lineales

Ventajas:
- Excelente para relaciones no lineales
- Robusto a outliers
- No requiere scaling de features
- Proporciona importancia de features

Desventajas:
- Menos interpretable
- Puede hacer overfitting con pocos datos
- Mayor tiempo de entrenamiento
```

### **5. Gradient Boosting**
```python
Modelo: GradientBoostingRegressor
Par谩metros: {
    'n_estimators': 100,
    'random_state': 42
}
Descripci贸n: Gradient Boosting

Caracter铆sticas:
- Ensemble secuencial de 谩rboles d茅biles
- Optimizaci贸n iterativa de errores
- Alta capacidad predictiva

Ventajas:
- Excelente performance predictiva
- Maneja interacciones complejas
- Robusto a outliers

Desventajas:
- Propenso a overfitting
- Lento entrenamiento
- Muchos hiperpar谩metros
- Menos interpretable
```

### **6. Support Vector Regression (SVR)**
```python
Modelo: SVR
Par谩metros: {
    'kernel': 'rbf',
    'C': 1.0
}
Descripci贸n: Support Vector Regression

Caracter铆sticas:
- Mapeo a espacio de alta dimensi贸n
- Kernel RBF para relaciones no lineales
- Tolerancia a errores con epsilon

Ventajas:
- Eficaz en alta dimensi贸n
- Vers谩til (diferentes kernels)
- Robusto a outliers

Desventajas:
- Lento con datasets grandes
- Requiere scaling de features
- Dif铆cil interpretaci贸n
- Sensible a hiperpar谩metros
```

### **7. K-Nearest Neighbors (KNN)**
```python
Modelo: KNeighborsRegressor
Par谩metros: {
    'n_neighbors': 5
}
Descripci贸n: K-Nearest Neighbors

Caracter铆sticas:
- Aprendizaje basado en instancias
- No param茅trico
- Predicci贸n por promedio de vecinos

Ventajas:
- Simple y intuitivo
- No asume distribuci贸n de datos
- Funciona bien con patrones locales

Desventajas:
- Sensible a curse of dimensionality
- Costoso computacionalmente en predicci贸n
- Sensible a escala de features
- Requiere mucha memoria
```

### **8. rbol de Decisi贸n**
```python
Modelo: DecisionTreeRegressor
Par谩metros: {
    'random_state': 42
}
Descripci贸n: rbol de Decisi贸n

Caracter铆sticas:
- Estructura jer谩rquica de decisiones
- Splits binarios por feature
- M谩xima interpretabilidad

Ventajas:
- Extremadamente interpretable
- Maneja relaciones no lineales
- No requiere scaling
- Selecci贸n autom谩tica de features

Desventajas:
- Propenso a overfitting
- Inestable (alta varianza)
- Sesgado hacia features con m谩s valores
- Puede crear reglas muy espec铆ficas
```

---

##  M茅tricas de Evaluaci贸n

### **M茅tricas Calculadas por Modelo**

```python
M茅tricas Primarias:
- RMSE: Ra铆z del Error Cuadr谩tico Medio
- MAE: Error Absoluto Medio  
- MedAE: Mediana del Error Absoluto
- R虏: Coeficiente de Determinaci贸n
- EVS: Varianza Explicada
- CV_R虏_mean: R虏 promedio en validaci贸n cruzada
- CV_R虏_std: Desviaci贸n est谩ndar de R虏 en CV
- MAPE: Error Porcentual Absoluto Medio
```

### **Interpretaci贸n de M茅tricas**

**RMSE (Root Mean Square Error)**
- Unidades: Mismas que variable objetivo (seguidores)
- Interpretaci贸n: Error promedio en predicciones
- Objetivo: Minimizar
- Sensible a outliers

**MAE (Mean Absolute Error)**
- Unidades: Mismas que variable objetivo
- Interpretaci贸n: Error absoluto promedio
- Objetivo: Minimizar
- Robusto a outliers

**R虏 (Coefficient of Determination)**
- Rango: [0, 1] (puede ser negativo si el modelo es muy malo)
- Interpretaci贸n: Porcentaje de varianza explicada
- Objetivo: Maximizar
- R虏 = 1 significa predicci贸n perfecta

**MAPE (Mean Absolute Percentage Error)**
- Unidades: Porcentaje
- Interpretaci贸n: Error porcentual promedio
- Objetivo: Minimizar
- til para comparar entre diferentes escalas

---

##  Selecci贸n del Mejor Modelo

### **Metodolog铆a de Selecci贸n**

```python
Algoritmo de Score Compuesto:
1. Normalizaci贸n min-max de todas las m茅tricas
2. Asignaci贸n de pesos por m茅trica
3. C谩lculo de score compuesto ponderado
4. Selecci贸n del modelo con mayor score

M茅tricas a Maximizar:
- R虏 (Coeficiente de determinaci贸n)
- EVS (Varianza explicada)  
- CV_R虏_mean (R虏 en validaci贸n cruzada)

M茅tricas a Minimizar:
- RMSE (Error cuadr谩tico medio)
- MAE (Error absoluto medio)
- MedAE (Mediana error absoluto)
- CV_R虏_std (Variabilidad en CV)
- MAPE (Error porcentual)
```

### **Pesos por Defecto**
```python
Pesos Equitativos: {
    'RMSE': 1/8,
    'MAE': 1/8,
    'MedAE': 1/8,
    'R虏': 1/8,
    'EVS': 1/8,
    'CV_R虏_mean': 1/8,
    'CV_R虏_std': 1/8,
    'MAPE': 1/8
}

Pesos Personalizables via API:
metric_weights = "{'R虏':0.3,'RMSE':0.3,'MAE':0.2,'MAPE':0.2}"
```

---

##  Salidas del Sistema

### **1. Respuesta de Entrenamiento**
```json
{
    "message": "Modelo de regresi贸n entrenado exitosamente para @username",
    "best_model": "Random Forest",
    "metrics": {
        "score_compuesto": 0.847,
        "R虏": 0.892,
        "RMSE": 1234.56,
        "MAE": 987.32,
        "MAPE": 5.67
    },
    "model_path": "models/username/regresion.pkl",
    "target_variable": "seguidores",
    "features_used": ["dia_semana", "hora", "mes"],
    "training_samples": 800,
    "test_samples": 200
}
```

### **2. Informaci贸n del Modelo**
```json
{
    "username": "Interbank",
    "target_variable": "seguidores",
    "model_type": "RandomForestRegressor",
    "model_id": "random_forest",
    "timestamp": "2025-07-12T14:30:45.123456",
    "results_count": 8
}
```

### **3. Predicci贸n Individual**
```json
{
    "prediction": 15420.5,
    "model_type": "RandomForestRegressor", 
    "target_variable": "seguidores"
}
```

### **4. M茅tricas Detalladas**
```json
{
    "account_name": "Interbank",
    "target_variable": "seguidores",
    "best_model": {
        "model_id": "random_forest",
        "model_name": "Random Forest",
        "score_compuesto": 0.847,
        "r2_score": 0.892,
        "rmse": 1234.56,
        "mae": 987.32
    },
    "all_results": [
        {
            "Modelo": "Random Forest",
            "R虏": 0.892,
            "RMSE": 1234.56,
            "MAE": 987.32,
            "CV_R虏_mean": 0.885
        }
    ],
    "feature_count": 3,
    "training_samples": 800,
    "test_samples": 200
}
```

---

##  Ejemplo de Uso

### **1. Entrenamiento con Pesos Personalizados**
```bash
# Entrenar con 茅nfasis en R虏 y RMSE
GET /regression/train/Interbank?metric_weights={"R虏":0.4,"RMSE":0.4,"MAE":0.2}

# Respuesta esperada
{
    "message": "Modelo entrenado exitosamente",
    "best_model": "Gradient Boosting",
    "metrics": {
        "score_compuesto": 0.923,
        "R虏": 0.945,
        "RMSE": 856.23,
        "MAE": 634.12
    }
}
```

### **2. Predicci贸n Individual**
```bash
# Predicci贸n para un lunes a las 14:00 en julio
GET /regression/predict/Interbank?fecha=2025-07-14

# Respuesta esperada
{
    "prediction": 18567.3,
    "model_type": "GradientBoostingRegressor",
    "target_variable": "seguidores"
}
```

### **3. Consulta de M茅tricas**
```bash
# Obtener m茅tricas detalladas del modelo
GET /regression/metrics/Interbank

# Respuesta: M茅tricas completas de todos los modelos evaluados
```

---

##  Resumen de Performance Esperado

### **Ranking T铆pico de Modelos por Sector Financiero**

1. **Random Forest** - Mejor balance precisi贸n/robustez
2. **Gradient Boosting** - M谩xima precisi贸n, riesgo overfitting  
3. **SVR** - Bueno con patrones complejos
4. **Ridge Regression** - Estable y confiable
5. **Decision Tree** - Interpretable pero inestable
6. **Linear Regression** - Baseline simple
7. **Lasso** - Bueno para selecci贸n de features
8. **KNN** - Dependiente de datos locales

### **M茅tricas Objetivo por Sector**
- **R虏 esperado:** 0.75 - 0.95
- **RMSE t铆pico:** 500 - 2000 seguidores  
- **MAE t铆pico:** 300 - 1500 seguidores
- **MAPE objetivo:** < 10%

---

##  Configuraci贸n T茅cnica

### **Requisitos del Sistema**
- Python 3.13+
- scikit-learn 1.3.2+
- pandas 2.1.4+
- numpy 1.26.2+

### **Archivos Generados**
- Modelo serializado: `models/{username}/regresion.pkl`
- M茅tricas: `metricas/{username}.json`
- Logs de entrenamiento: Sistema de logging integrado

### **Consideraciones de Producci贸n**
- Validaci贸n de entrada robusta
- Manejo de errores comprehensivo
- Logging detallado de operaciones
- Respaldo autom谩tico de modelos
- Monitoreo de performance en tiempo real

---

**Este documento constituye la especificaci贸n t茅cnica completa para los 8 modelos de regresi贸n implementados en TwiTrack API v3.0.0**
