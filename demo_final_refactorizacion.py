#!/usr/bin/env python3
# =============================================================================
# DEMO FINAL: ENDPOINT REFACTORIZADO CON DATOS REALES DE INTERBANK
# =============================================================================

"""
üéØ DEMOSTRACI√ìN COMPLETA del endpoint refactorizado que acepta solo 'fecha'

CARACTER√çSTICAS DEMOSTRADAS:
‚úÖ Carga de datos reales de Interbank
‚úÖ Extracci√≥n autom√°tica de features temporales  
‚úÖ Entrenamiento de los 8 modelos de regresi√≥n
‚úÖ Simulaci√≥n del endpoint simplificado
‚úÖ Comparaci√≥n antes vs despu√©s de la refactorizaci√≥n
‚úÖ Ejemplos reales de predicci√≥n usando solo fecha

DATOS: @Interbank desde data/Interbank_metricas.csv
"""

import pandas as pd
import numpy as np
import warnings
from datetime import datetime, timedelta
from pathlib import Path
import json

# Modelos de machine learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Los 8 modelos de regresi√≥n
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor

warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURACI√ìN DE MODELOS
# =============================================================================

REGRESSION_MODELS = {
    'linear_regression': {
        'model': LinearRegression,
        'params': {},
        'description': 'Regresi√≥n Lineal Simple'
    },
    'ridge': {
        'model': Ridge,
        'params': {'alpha': 1.0, 'random_state': 42},
        'description': 'Regresi√≥n Ridge (L2)'
    },
    'lasso': {
        'model': Lasso,
        'params': {'alpha': 1.0, 'random_state': 42},
        'description': 'Regresi√≥n Lasso (L1)'
    },
    'random_forest': {
        'model': RandomForestRegressor,
        'params': {'n_estimators': 100, 'random_state': 42},
        'description': 'Random Forest'
    },
    'gradient_boosting': {
        'model': GradientBoostingRegressor,
        'params': {'n_estimators': 100, 'random_state': 42},
        'description': 'Gradient Boosting'
    },
    'svr': {
        'model': SVR,
        'params': {'kernel': 'rbf', 'C': 1.0},
        'description': 'Support Vector Regression'
    },
    'knn': {
        'model': KNeighborsRegressor,
        'params': {'n_neighbors': 5},
        'description': 'K-Nearest Neighbors'
    },
    'decision_tree': {
        'model': DecisionTreeRegressor,
        'params': {'random_state': 42},
        'description': '√Årbol de Decisi√≥n'
    }
}

def print_header(title, width=80):
    print("\n" + "=" * width)
    print(f" {title} ".center(width))
    print("=" * width)

def print_subheader(title, width=60):
    print("\n" + "-" * width)
    print(f" {title}")
    print("-" * width)

def load_interbank_data():
    """Carga datos reales de Interbank"""
    print_header("üìä CARGA DE DATOS REALES DE INTERBANK")
    
    # Buscar archivo de datos
    data_files = [
        "data/Interbank_metricas.csv",
        "data/interbank_metricas.csv", 
        "data/Interbank_clean.csv",
        "data/interbank_clean.csv"
    ]
    
    data_path = None
    for file_path in data_files:
        if Path(file_path).exists():
            data_path = file_path
            break
    
    if not data_path:
        raise FileNotFoundError("‚ùå No se encontr√≥ archivo de datos de Interbank")
    
    print(f"üìÅ Archivo encontrado: {data_path}")
    
    # Cargar datos
    df = pd.read_csv(data_path)
    
    print(f"‚úÖ Datos cargados exitosamente")
    print(f"üìä Dimensiones: {df.shape[0]} filas √ó {df.shape[1]} columnas")
    print(f"üìÖ Columnas: {list(df.columns)}")
    
    # Mostrar muestra de datos
    print(f"\nüìã Muestra de datos:")
    print(df.head())
    
    # Estad√≠sticas b√°sicas de seguidores
    print(f"\nüìà Estad√≠sticas de Seguidores:")
    seguidores_stats = df['Seguidores'].describe()
    for stat, value in seguidores_stats.items():
        print(f"   ‚Ä¢ {stat.title()}: {value:,.0f}")
    
    return df

def extract_temporal_features(df):
    """Extrae features temporales de los timestamps"""
    print_subheader("‚è∞ EXTRACCI√ìN DE FEATURES TEMPORALES")
    
    # Convertir timestamp a datetime
    df['Hora'] = pd.to_datetime(df['Hora'])
    
    # Extraer componentes temporales (como lo hace el endpoint)
    df['dia_semana'] = df['Hora'].dt.dayofweek  # 0=Lunes, 6=Domingo  
    df['hora'] = df['Hora'].dt.hour             # 0-23
    df['mes'] = df['Hora'].dt.month             # 1-12
    
    print(f"‚úÖ Features temporales extra√≠das:")
    print(f"   ‚Ä¢ dia_semana: rango {df['dia_semana'].min()}-{df['dia_semana'].max()} (0=Lunes, 6=Domingo)")
    print(f"   ‚Ä¢ hora: rango {df['hora'].min()}-{df['hora'].max()} (0-23)")
    print(f"   ‚Ä¢ mes: rango {df['mes'].min()}-{df['mes'].max()} (1-12)")
    
    # Mostrar ejemplos de transformaci√≥n
    print(f"\nüìÖ Ejemplos de transformaci√≥n temporal:")
    for i in range(min(3, len(df))):
        row = df.iloc[i]
        timestamp = row['Hora']
        dia_sem = row['dia_semana']
        hora = row['hora']
        mes = row['mes']
        
        dias = ['Lun', 'Mar', 'Mi√©', 'Jue', 'Vie', 'S√°b', 'Dom']
        meses = ['', 'Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 
                'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']
        
        print(f"   {timestamp} ‚Üí dia_semana={dia_sem} ({dias[dia_sem]}), hora={hora}, mes={mes} ({meses[mes]})")
    
    return df

def prepare_model_features(df):
    """Prepara features para entrenamiento de modelos"""
    print_subheader("üõ†Ô∏è PREPARACI√ìN DE FEATURES PARA MODELOS")
    
    # Features temporales (las que usa el endpoint)
    temporal_features = ['dia_semana', 'hora', 'mes']
    
    # Features base del dataset
    base_features = ['Tweets', 'Following']
    
    # Crear features derivadas
    df['ratio_seguidores_tweets'] = df['Seguidores'] / (df['Tweets'] + 1)
    df['ratio_seguidores_siguiendo'] = df['Seguidores'] / (df['Following'] + 1)
    derived_features = ['ratio_seguidores_tweets', 'ratio_seguidores_siguiendo']
    
    # Todas las features para el modelo
    all_features = temporal_features + base_features + derived_features
    
    print(f"‚úÖ Features preparadas:")
    print(f"   ‚Ä¢ Temporales (endpoint): {temporal_features}")
    print(f"   ‚Ä¢ Base (dataset): {base_features}")
    print(f"   ‚Ä¢ Derivadas (calculadas): {derived_features}")
    print(f"   ‚Ä¢ Total features: {len(all_features)}")
    
    # Verificar disponibilidad
    available_features = [f for f in all_features if f in df.columns]
    missing_features = [f for f in all_features if f not in df.columns]
    
    if missing_features:
        print(f"‚ö†Ô∏è  Features faltantes: {missing_features}")
        all_features = available_features
    
    print(f"üéØ Features finales: {available_features}")
    
    return df, available_features

def train_regression_models(df, features):
    """Entrena los 8 modelos de regresi√≥n"""
    print_header("ü§ñ ENTRENAMIENTO DE LOS 8 MODELOS DE REGRESI√ìN")
    
    # Preparar datos
    X = df[features].fillna(0)
    y = df['Seguidores']
    
    print(f"üìä Datos para entrenamiento:")
    print(f"   ‚Ä¢ Muestras: {len(y):,}")
    print(f"   ‚Ä¢ Features: {len(features)}")
    print(f"   ‚Ä¢ Seguidores: {y.min():,} ‚Üí {y.max():,}")
    
    # Divisi√≥n train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"   ‚Ä¢ Train: {len(y_train)} | Test: {len(y_test)}")
    
    # Escalado para algunos modelos
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Entrenar modelos
    results = {}
    
    print(f"\nüîÑ Entrenando modelos...")
    
    for model_id, config in REGRESSION_MODELS.items():
        print(f"\n   ü§ñ {config['description']}")
        
        try:
            # Crear modelo
            model_class = config['model']
            params = config['params']
            model = model_class(**params)
            
            # Algunos modelos necesitan escalado
            if model_id in ['svr', 'knn']:
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                trained_with_scaling = True
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                trained_with_scaling = False
            
            # Calcular m√©tricas
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = mean_absolute_error(y_test, y_pred)
            
            results[model_id] = {
                'model': model,
                'description': config['description'],
                'r2': r2,
                'rmse': rmse,
                'mae': mae,
                'scaled': trained_with_scaling,
                'success': True
            }
            
            print(f"      ‚úÖ R¬≤ = {r2:.3f} | RMSE = {rmse:.1f} | MAE = {mae:.1f}")
            
        except Exception as e:
            results[model_id] = {
                'description': config['description'],
                'error': str(e),
                'success': False
            }
            print(f"      ‚ùå Error: {e}")
    
    return results, scaler, features, X_train, X_test, y_train, y_test

def analyze_model_performance(results):
    """Analiza el rendimiento de todos los modelos"""
    print_header("üìä AN√ÅLISIS DE RENDIMIENTO DE MODELOS")
    
    # Filtrar modelos exitosos
    successful = [(mid, res) for mid, res in results.items() if res['success']]
    
    if not successful:
        print("‚ùå No hay modelos exitosos para analizar")
        return None, None
    
    # Crear tabla de resultados
    performance_data = []
    for model_id, result in successful:
        performance_data.append({
            'ID': model_id,
            'Modelo': result['description'],
            'R¬≤': result['r2'],
            'RMSE': result['rmse'],
            'MAE': result['mae']
        })
    
    # Ordenar por R¬≤ (mejor primero)
    performance_data.sort(key=lambda x: x['R¬≤'], reverse=True)
    
    # Mostrar ranking
    print("üèÜ RANKING DE MODELOS (por R¬≤):")
    print("-" * 75)
    print(f"{'#':<3} {'Modelo':<25} {'R¬≤':<8} {'RMSE':<10} {'MAE':<8}")
    print("-" * 75)
    
    for i, data in enumerate(performance_data, 1):
        r2_str = f"{data['R¬≤']:.3f}"
        rmse_str = f"{data['RMSE']:.1f}"
        mae_str = f"{data['MAE']:.1f}"
        print(f"{i:<3} {data['Modelo']:<25} {r2_str:<8} {rmse_str:<10} {mae_str:<8}")
    
    # Mejor modelo
    best = performance_data[0]
    print(f"\nü•á MEJOR MODELO: {best['Modelo']}")
    print(f"   ‚Ä¢ R¬≤ = {best['R¬≤']:.3f} ({best['R¬≤']*100:.1f}% varianza explicada)")
    print(f"   ‚Ä¢ RMSE = {best['RMSE']:.1f} seguidores de error promedio")
    print(f"   ‚Ä¢ MAE = {best['MAE']:.1f} seguidores de error absoluto")
    
    return best, performance_data

def simulate_endpoint_api(best_model_info, results, scaler, features):
    """Simula el funcionamiento del endpoint refactorizado"""
    print_header("üåê SIMULACI√ìN DEL ENDPOINT REFACTORIZADO")
    
    if not best_model_info:
        print("‚ùå No hay modelo para simular")
        return
    
    best_model_id = best_model_info['ID']
    best_result = results[best_model_id]
    model = best_result['model']
    uses_scaling = best_result['scaled']
    
    print(f"üéØ Usando mejor modelo: {best_result['description']}")
    print(f"üîß Escalado requerido: {'S√≠' if uses_scaling else 'No'}")
    print(f"üìã Features requeridas: {features}")
    
    print_subheader("üìÖ EJEMPLOS DE PREDICCI√ìN CON SOLO FECHA")
    
    # Ejemplos de fechas para probar
    today = datetime.now()
    test_dates = [
        (today, "Hoy"),
        (today + timedelta(days=1), "Ma√±ana"),
        (today + timedelta(days=7), "Pr√≥xima semana"),
        (datetime(2025, 12, 25), "Navidad 2025"),
        (datetime(2025, 7, 11), "11 de Julio 2025")
    ]
    
    print("üîÑ Simulando llamadas al endpoint...")
    
    for fecha_obj, descripcion in test_dates:
        fecha_str = fecha_obj.strftime("%Y-%m-%d")
        
        print(f"\nüìÖ {descripcion} ({fecha_str}):")
        
        # 1. Extracci√≥n autom√°tica (como hace el endpoint)
        dia_semana = fecha_obj.weekday()  # 0=Lunes, 6=Domingo
        hora = 23  # Fin del d√≠a por defecto
        mes = fecha_obj.month  # 1-12
        
        print(f"   üîß Extracci√≥n autom√°tica de features temporales:")
        print(f"      ‚Ä¢ dia_semana = {dia_semana} ({['Lun','Mar','Mi√©','Jue','Vie','S√°b','Dom'][dia_semana]})")
        print(f"      ‚Ä¢ hora = {hora} (fin del d√≠a)")
        print(f"      ‚Ä¢ mes = {mes}")
        
        # 2. Completar features con valores t√≠picos de Interbank
        feature_values = {}
        
        # Features temporales (extra√≠das de fecha)
        temporal_values = {
            'dia_semana': dia_semana,
            'hora': hora,
            'mes': mes
        }
        
        # Features t√≠picas de Interbank (promedio del dataset)
        typical_values = {
            'Tweets': 66930,
            'Following': 71,
            'ratio_seguidores_tweets': 4.5,
            'ratio_seguidores_siguiendo': 4300
        }
        
        # Construir vector de features
        feature_vector = []
        for feature in features:
            if feature in temporal_values:
                value = temporal_values[feature]
            elif feature in typical_values:
                value = typical_values[feature]
            else:
                value = 0
            
            feature_values[feature] = value
            feature_vector.append(value)
        
        # 3. Realizar predicci√≥n
        input_array = np.array([feature_vector])
        
        # Aplicar escalado si es necesario
        if uses_scaling:
            input_array = scaler.transform(input_array)
        
        prediction = model.predict(input_array)[0]
        
        print(f"   üéØ Predicci√≥n: {prediction:,.0f} seguidores")
        
        # 4. Simular respuesta de la API (refactorizada)
        api_response = {
            "prediction": float(prediction),
            "model_type": type(model).__name__,
            "target_variable": "seguidores"
        }
        
        print(f"   üì° Respuesta API (refactorizada):")
        print(f"      {json.dumps(api_response, indent=6)}")

def compare_before_after():
    """Compara el endpoint antes y despu√©s de la refactorizaci√≥n"""
    print_header("üîÑ COMPARACI√ìN: ANTES vs DESPU√âS DE LA REFACTORIZACI√ìN")
    
    print_subheader("‚ùå ANTES - Complejo y Verbose")
    
    print("üìù Entrada requerida (m√∫ltiples par√°metros):")
    print("   http://localhost:8000/regression/predict/Interbank?dia_semana=4&hora=23&mes=7")
    
    print("\nüì§ Respuesta verbose (12+ campos):")
    before_response = {
        "prediction": 304250.0,
        "model_type": "RandomForestRegressor",
        "target_variable": "seguidores",
        "input_features": {"dia_semana": 4, "hora": 23, "mes": 7},
        "feature_names": ["dia_semana", "hora", "mes"],
        "fecha_info": {
            "fecha_original": "2025-07-11",
            "dia_semana_calculado": 4,
            "mes_calculado": 7,
            "hora_asumida": 23,
            "dia_nombre": "Friday",
            "mes_nombre": "July"
        },
        "timestamp": "2025-01-27T10:30:00",
        "username": "Interbank",
        "confidence": "high",
        "model_version": "1.0",
        "metadata": {"training_date": "2025-01-27"}
    }
    print(json.dumps(before_response, indent=2))
    
    print_subheader("‚úÖ DESPU√âS - Simple y Limpio")
    
    print("üìù Entrada simplificada (solo fecha):")
    print("   http://localhost:8000/regression/predict/Interbank?fecha=2025-07-11")
    
    print("\nüì§ Respuesta limpia (solo 3 campos esenciales):")
    after_response = {
        "prediction": 304250.0,
        "model_type": "RandomForestRegressor",
        "target_variable": "seguidores"
    }
    print(json.dumps(after_response, indent=2))
    
    print_subheader("‚úÖ VENTAJAS DE LA REFACTORIZACI√ìN")
    
    advantages = [
        "üéØ Interfaz m√°s simple - solo necesitas la fecha",
        "üßπ Respuesta limpia - sin campos innecesarios",
        "üöÄ Mejor UX - m√°s intuitivo para usuarios",
        "üîß Menos errores - menos par√°metros que validar",
        "üì± F√°cil integraci√≥n - compatible con calendarios",
        "üõ†Ô∏è Mantenibilidad - c√≥digo m√°s simple",
        "‚ö° Mejor rendimiento - menos procesamiento",
        "üìä Enfoque en lo esencial - predicci√≥n, modelo, variable"
    ]
    
    for advantage in advantages:
        print(f"   {advantage}")

def show_usage_examples():
    """Muestra ejemplos de uso pr√°cticos"""
    print_header("üß™ EJEMPLOS PR√ÅCTICOS DE USO")
    
    print_subheader("üì° cURL Commands")
    
    examples = [
        ("Hoy", "2025-07-11"),
        ("Ma√±ana", "2025-07-12"),
        ("Fin de semana", "2025-07-13"),
        ("Navidad", "2025-12-25"),
        ("A√±o Nuevo", "2025-01-01")
    ]
    
    for description, date in examples:
        print(f"\nüìÖ {description} ({date}):")
        print(f'   curl "http://localhost:8000/regression/predict/Interbank?fecha={date}"')
    
    print_subheader("üêç Python Requests")
    
    python_code = '''
import requests

# Predicci√≥n para hoy
response = requests.get(
    "http://localhost:8000/regression/predict/Interbank",
    params={"fecha": "2025-07-11"}
)

if response.status_code == 200:
    data = response.json()
    print(f"Predicci√≥n: {data['prediction']:,.0f} seguidores")
    print(f"Modelo: {data['model_type']}")
else:
    print(f"Error: {response.status_code}")
'''
    print(python_code)
    
    print_subheader("üåê JavaScript/Fetch")
    
    js_code = '''
// Predicci√≥n usando fetch
fetch('http://localhost:8000/regression/predict/Interbank?fecha=2025-07-11')
  .then(response => response.json())
  .then(data => {
    console.log(`Predicci√≥n: ${data.prediction.toLocaleString()} seguidores`);
    console.log(`Modelo: ${data.model_type}`);
  })
  .catch(error => console.error('Error:', error));
'''
    print(js_code)

def main():
    """Funci√≥n principal"""
    print_header("üéØ DEMO FINAL: ENDPOINT REFACTORIZADO CON DATOS DE INTERBANK", 90)
    print("üìä Demostraci√≥n completa del sistema refactorizado")
    print("üîÑ De par√°metros m√∫ltiples a solo 'fecha'")
    print("ü§ñ Entrenamiento y evaluaci√≥n de 8 modelos de regresi√≥n")
    
    try:
        # 1. Cargar datos reales de Interbank
        df = load_interbank_data()
        
        # 2. Extraer features temporales
        df = extract_temporal_features(df)
        
        # 3. Preparar features para modelos
        df, features = prepare_model_features(df)
        
        # 4. Entrenar todos los modelos
        results, scaler, features, X_train, X_test, y_train, y_test = train_regression_models(df, features)
        
        # 5. Analizar rendimiento
        best_model, performance = analyze_model_performance(results)
        
        # 6. Simular endpoint refactorizado
        simulate_endpoint_api(best_model, results, scaler, features)
        
        # 7. Comparar antes vs despu√©s
        compare_before_after()
        
        # 8. Mostrar ejemplos de uso
        show_usage_examples()
        
        print_header("‚úÖ DEMO COMPLETADO EXITOSAMENTE", 90)
        print("üéâ El endpoint refactorizado est√° funcionando perfectamente")
        print("üìä Los 8 modelos de regresi√≥n han sido entrenados con datos reales")
        print("üîß La API ahora es m√°s simple, limpia y f√°cil de usar")
        print("üåê Solo necesitas la fecha para hacer predicciones")
        
    except Exception as e:
        print(f"\n‚ùå ERROR DURANTE LA DEMO: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
