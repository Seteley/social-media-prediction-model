# =============================================================================
# CARGA Y CONSOLIDACIÃ“N DE DATOS
# =============================================================================

"""
MÃ³dulo para la carga automÃ¡tica y consolidaciÃ³n de datos de Twitter.
Busca archivos *_clean.csv y los consolida en un DataFrame Ãºnico.
"""

import os
import glob
import pandas as pd
from typing import Tuple, List, Dict, Optional
from config import PROJECT_CONFIG

class DataLoader:
    """
    Clase para manejar la carga y consolidaciÃ³n de datos de Twitter.
    """
    
    def __init__(self, data_folder: str = None, file_pattern: str = None):
        """
        Inicializa el cargador de datos.
        
        Args:
            data_folder (str): Carpeta donde buscar los datos
            file_pattern (str): PatrÃ³n de archivos a buscar
        """
        self.data_folder = data_folder or PROJECT_CONFIG['data_folder']
        self.file_pattern = file_pattern or PROJECT_CONFIG['file_pattern']
        
    def find_data_files(self) -> List[str]:
        """
        Busca archivos de datos limpios en la carpeta especificada.
        
        Returns:
            List[str]: Lista de rutas de archivos encontrados
            
        Raises:
            FileNotFoundError: Si no se encuentran archivos
        """
        search_pattern = os.path.join(self.data_folder, self.file_pattern)
        csv_files = glob.glob(search_pattern)
        
        if not csv_files:
            raise FileNotFoundError(
                f"âŒ No se encontraron archivos {self.file_pattern} en la carpeta {self.data_folder}/.\n"
                "AsegÃºrate de que los datos estÃ©n procesados y guardados correctamente."
            )
        
        return csv_files
    
    def load_single_file(self, file_path: str) -> Tuple[pd.DataFrame, str]:
        """
        Carga un solo archivo CSV y extrae informaciÃ³n del usuario.
        
        Args:
            file_path (str): Ruta del archivo a cargar
            
        Returns:
            Tuple[pd.DataFrame, str]: DataFrame cargado y nombre del usuario
        """
        # Extraer nombre del usuario del archivo
        usuario = os.path.basename(file_path).replace('_clean.csv', '')
        
        # Cargar datos
        df = pd.read_csv(file_path)
        df['usuario'] = usuario
        
        return df, usuario
    
    def consolidate_data(self) -> Tuple[pd.DataFrame, Dict]:
        """
        Consolida todos los archivos de datos en un DataFrame Ãºnico.
        
        Returns:
            Tuple[pd.DataFrame, Dict]: DataFrame consolidado e informaciÃ³n del proceso
        """
        csv_files = self.find_data_files()
        
        print(f"ðŸ“ Archivos encontrados: {len(csv_files)}")
        for file in csv_files:
            print(f"   â€¢ {os.path.basename(file)}")
        
        # ConsolidaciÃ³n de datos
        usuarios = []
        dfs = []
        total_tweets = 0
        
        for file in csv_files:
            df, usuario = self.load_single_file(file)
            
            # InformaciÃ³n del archivo
            print(f"ðŸ“Š {usuario}: {len(df):,} tweets")
            total_tweets += len(df)
            
            # Almacenar
            dfs.append(df)
            usuarios.append(usuario)
        
        # Concatenar todos los DataFrames
        data = pd.concat(dfs, ignore_index=True)
        
        # InformaciÃ³n de consolidaciÃ³n
        consolidation_info = {
            'total_usuarios': len(usuarios),
            'total_tweets': total_tweets,
            'shape': data.shape,
            'usuarios': usuarios,
            'archivos_procesados': len(csv_files)
        }
        
        print(f"\nâœ… Datos consolidados exitosamente:")
        print(f"   â€¢ Total de usuarios: {len(usuarios)}")
        print(f"   â€¢ Total de tweets: {total_tweets:,}")
        print(f"   â€¢ Dimensiones finales: {data.shape}")
        print(f"   â€¢ Usuarios disponibles: {', '.join(usuarios)}")
        
        return data, consolidation_info
    
    def select_scope(self, data: pd.DataFrame, usuario_objetivo: str = 'interbank') -> Tuple[pd.DataFrame, str]:
        """
        Selecciona el scope de anÃ¡lisis (usuario especÃ­fico o todos).
        
        Args:
            data (pd.DataFrame): DataFrame consolidado
            usuario_objetivo (str): Usuario especÃ­fico o 'todos'
            
        Returns:
            Tuple[pd.DataFrame, str]: Datos filtrados y mensaje de scope
        """
        usuarios_disponibles = data['usuario'].unique()
        
        print("ðŸ‘¥ Usuarios disponibles para anÃ¡lisis:")
        for i, usuario in enumerate(usuarios_disponibles, 1):
            tweets_count = len(data[data['usuario'] == usuario])
            print(f"   {i}. {usuario.capitalize()}: {tweets_count:,} tweets")
        
        print(f"\nðŸ“ Para analizar todos los usuarios, usa: 'todos'")
        
        # ValidaciÃ³n y filtrado
        if usuario_objetivo.lower() == 'todos':
            data_filtrada = data.copy()
            scope_msg = "ðŸŒ AnÃ¡lisis de TODOS los usuarios"
        elif usuario_objetivo in usuarios_disponibles:
            data_filtrada = data[data['usuario'] == usuario_objetivo].copy()
            scope_msg = f"ðŸŽ¯ AnÃ¡lisis especÃ­fico de: {usuario_objetivo.upper()}"
        else:
            available_options = ", ".join(usuarios_disponibles) + ", todos"
            raise ValueError(
                f"âŒ Usuario '{usuario_objetivo}' no encontrado.\n"
                f"Opciones disponibles: {available_options}"
            )
        
        # InformaciÃ³n del dataset filtrado
        print(f"\n{scope_msg}")
        print(f"ðŸ“Š Datos seleccionados: {data_filtrada.shape[0]:,} tweets, {data_filtrada.shape[1]} columnas")
        
        # EstadÃ­sticas especÃ­ficas del scope
        self._print_scope_statistics(data_filtrada, usuario_objetivo, usuarios_disponibles)
        
        return data_filtrada, scope_msg
    
    def _print_scope_statistics(self, data_filtrada: pd.DataFrame, usuario_objetivo: str, usuarios_disponibles: List[str]):
        """
        Imprime estadÃ­sticas especÃ­ficas del scope seleccionado.
        
        Args:
            data_filtrada (pd.DataFrame): Datos filtrados
            usuario_objetivo (str): Usuario objetivo
            usuarios_disponibles (List[str]): Lista de usuarios disponibles
        """
        if usuario_objetivo.lower() != 'todos':
            if 'fecha_publicacion' in data_filtrada.columns:
                fecha_inicio = data_filtrada['fecha_publicacion'].min()
                fecha_fin = data_filtrada['fecha_publicacion'].max()
                print(f"ðŸ“… PerÃ­odo: {fecha_inicio} - {fecha_fin}")
            
            # MÃ©tricas promedio del usuario seleccionado
            metricas_cols = ['respuestas', 'retweets', 'likes', 'guardados', 'vistas']
            metricas_disponibles = [col for col in metricas_cols if col in data_filtrada.columns]
            
            if metricas_disponibles:
                print(f"\nðŸ“ˆ MÃ©tricas promedio del usuario {usuario_objetivo.title()}:")
                metricas_promedio = data_filtrada[metricas_disponibles].mean()
                for metrica, valor in metricas_promedio.items():
                    print(f"   â€¢ {metrica.title()}: {valor:.1f}")
        else:
            if 'fecha_publicacion' in data_filtrada.columns:
                fecha_min = data_filtrada['fecha_publicacion'].min()
                fecha_max = data_filtrada['fecha_publicacion'].max()
                print(f"ðŸ“… PerÃ­odo total del dataset: {fecha_min} - {fecha_max}")
            
            # MÃ©tricas por usuario cuando se analizan todos
            print(f"\nðŸ“ˆ Resumen por usuario:")
            for usuario in usuarios_disponibles:
                usuario_data = data_filtrada[data_filtrada['usuario'].str.upper() == usuario.upper()]
                if len(usuario_data) > 0:
                    print(f"   â€¢ {usuario.title()}: {len(usuario_data)} tweets")

def load_and_prepare_data(usuario_objetivo: str = 'interbank', 
                         data_folder: str = None) -> Tuple[pd.DataFrame, Dict]:
    """
    FunciÃ³n principal para cargar y preparar datos.
    
    Args:
        usuario_objetivo (str): Usuario especÃ­fico o 'todos'
        data_folder (str): Carpeta de datos (opcional)
        
    Returns:
        Tuple[pd.DataFrame, Dict]: Datos preparados e informaciÃ³n del proceso
    """
    loader = DataLoader(data_folder=data_folder)
    
    # Consolidar datos
    data_consolidada, consolidation_info = loader.consolidate_data()
    
    # Seleccionar scope
    data_filtrada, scope_msg = loader.select_scope(data_consolidada, usuario_objetivo)
    
    # Vista previa
    print(f"\nðŸ“‹ Vista previa del dataset filtrado:")
    print(data_filtrada.head())
    
    # InformaciÃ³n completa del proceso
    process_info = {
        **consolidation_info,
        'scope_message': scope_msg,
        'usuario_objetivo': usuario_objetivo,
        'shape_filtrada': data_filtrada.shape
    }
    
    return data_filtrada, process_info

if __name__ == "__main__":
    # Ejemplo de uso
    data, info = load_and_prepare_data(usuario_objetivo='interbank')
    print(f"\nâœ… Proceso de carga completado. Shape final: {data.shape}")
